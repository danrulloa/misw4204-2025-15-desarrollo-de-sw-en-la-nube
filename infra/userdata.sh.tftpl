#!/bin/bash
set -eux

ROLE="${role}"
REPO_URL="${repo_url}"
repo_branch="${repo_branch}"
COMPOSE_FILE="${compose_file}"

core_ip="${core_ip}"
db_ip="${db_ip}"
mq_ip="${mq_ip}"
obs_ip="${obs_ip}"
web_ip="${web_ip}"
worker_ip="${worker_ip}"
alb_dns="${alb_dns}"

# RDS endpoints (vacíos si no se usan RDS)
rds_core_endpoint="${rds_core_endpoint}"
rds_auth_endpoint="${rds_auth_endpoint}"
rds_password="${rds_password}"

# S3 bucket (vacío si no se usa S3)
s3_bucket="${s3_bucket}"
aws_access_key_id="${aws_access_key_id}"
aws_secret_access_key="${aws_secret_access_key}"
aws_session_token="${aws_session_token}"
aws_region="${aws_region}"

apt-get update -y
apt-get install -y ca-certificates curl gnupg lsb-release git
install -m 0755 -d /etc/apt/keyrings || true
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
https://download.docker.com/linux/ubuntu $(. /etc/os-release; echo "$VERSION_CODENAME") stable" \
> /etc/apt/sources.list.d/docker.list
apt-get update -y
apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
systemctl enable --now docker
usermod -aG docker ubuntu || true

mkdir -p /opt/anb-cloud
cd /opt/anb-cloud
if [ ! -d .git ]; then
  git clone "$REPO_URL" /opt/anb-cloud
fi
git fetch --all
git checkout "$repo_branch"
git reset --hard "origin/${repo_branch}"

# ----- .env por rol -----
# Configuración estricta: requerimos ALB DNS; sin ALB no continuamos
if [ -z "$alb_dns" ]; then
  echo "ERROR: alb_dns no está definido. Terraform debe pasar el DNS del ALB." >&2
  exit 1
fi
LOKI_URL_VALUE="http://$alb_dns/loki/api/v1/push"

cat > /opt/anb-cloud/.env <<EOF
APP_ENV=production
API_TAG=latest
LOKI_URL=$LOKI_URL_VALUE

# CORE & AUTH DBs
POSTGRES_USER=anb_user
POSTGRES_PASSWORD=anb_pass
POSTGRES_CORE_DB=anb_core
POSTGRES_AUTH_DB=anb_auth

ACCESS_TOKEN_SECRET_KEY=mi_clave_de_acceso_secreta
REFRESH_TOKEN_SECRET_KEY=mi_clave_de_refresh_secreta
TOKEN_EXPIRE=600
REFRESH_TOKEN_EXPIRE=600
# RDS o PostgreSQL local según disponibilidad
%{ if rds_core_endpoint != "" ~}
DB_URL_CORE=postgresql+asyncpg://anb_user:${rds_password}@${rds_core_endpoint}:5432/anb_core
DB_URL_AUTH=postgresql+asyncpg://anb_user:${rds_password}@${rds_auth_endpoint}:5432/anb_auth
%{ else ~}
DB_URL_CORE=postgresql+asyncpg://anb_user:anb_pass@${db_ip}:5432/anb_core
DB_URL_AUTH=postgresql+asyncpg://anb_user:anb_pass@${db_ip}:5433/anb_auth
%{ endif ~}

# MQ
RABBITMQ_DEFAULT_USER=rabbit
RABBITMQ_DEFAULT_PASS=rabbitpass
RABBITMQ_PORT=5672
RABBITMQ_VHOST=/
RABBITMQ_URL=amqp://rabbit:rabbitpass@${mq_ip}:5672/%2F
RABBITMQ_HOST=${mq_ip}

# WEB upstreams
UPSTREAM_API=http://${core_ip}:8000
UPSTREAM_AUTH=http://${core_ip}:8001

# JWT & Security
JWT_SECRET=mi_secreto_super_seguro_para_jwt_tokens_2024
ALGORITHM=HS256

# S3 Configuration (si bucket está definido)
%{ if s3_bucket != "" ~}
STORAGE_BACKEND=s3
S3_BUCKET=${s3_bucket}
S3_REGION=${aws_region}
S3_PREFIX=uploads
S3_FORCE_PATH_STYLE=0
S3_VERIFY_SSL=1
# Credenciales explícitas para S3 (fail-fast en la app si faltan)
AWS_ACCESS_KEY_ID=${aws_access_key_id}
AWS_SECRET_ACCESS_KEY=${aws_secret_access_key}
AWS_SESSION_TOKEN=${aws_session_token}
%{ else ~}
STORAGE_BACKEND=local
%{ endif ~}
EOF

# Configurar prometheus con IPs dinámicas solo en OBS
if [ "$ROLE" = "obs" ]; then
  # External URL para que la UI de Prometheus genere enlaces con el prefijo /prometheus
  if [ -n "$alb_dns" ]; then
    echo "PROMETHEUS_EXTERNAL_URL=http://$alb_dns/prometheus" >> /opt/anb-cloud/.env
  fi
  # Usar el archivo base y sustituir placeholders con IPs reales
  # Evitar ciclos: solo sustituir WEB_IP si viene no vacío
  if [ -n "${web_ip}" ]; then
    sed -i "s/__WEB_IP__/${web_ip}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  fi
  sed -i "s/__CORE_IP__/${core_ip}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  sed -i "s/__DB_IP__/${db_ip}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  sed -i "s/__MQ_IP__/${mq_ip}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  sed -i "s/__WORKER_IP__/${worker_ip}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  # Si no recibimos obs_ip desde Terraform, consultamos a IMDS la IP privada
  if [ -z "${obs_ip}" ]; then
    obs_ip_runtime="$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4 || true)"
  else
    obs_ip_runtime="${obs_ip}"
  fi
  if [ -n "$${obs_ip_runtime}" ]; then
    sed -i "s/__OBS_IP__/$${obs_ip_runtime}/g" /opt/anb-cloud/observability/prometheus/prometheus.yml
  fi
  # Si quedaron entradas con __WEB_IP__ (no hay VM WEB), elimínalas para evitar targets inválidos
  sed -i '/__WEB_IP__/d' /opt/anb-cloud/observability/prometheus/prometheus.yml || true
fi

# Configurar nginx con IPs dinámicas solo en WEB
if [ "$ROLE" = "web" ]; then
  # Generar nginx.conf con las IPs correctas
  sed -i "s/__CORE_IP__/${core_ip}/g" /opt/anb-cloud/nginx/nginx.conf
  sed -i "s/__MQ_IP__/${mq_ip}/g" /opt/anb-cloud/nginx/nginx.conf  
  sed -i "s/__OBS_IP__/${obs_ip}/g" /opt/anb-cloud/nginx/nginx.conf
fi

# ----- Arranque por perfil -----
case "$ROLE" in
  web)    docker compose -f "$COMPOSE_FILE" --profile web    up -d ;;
  core)   docker compose -f "$COMPOSE_FILE" --profile core   up -d ;;
  db)     docker compose -f "$COMPOSE_FILE" --profile db     up -d ;;
  mq)     docker compose -f "$COMPOSE_FILE" --profile mq     up -d ;;
  worker) docker compose -f "$COMPOSE_FILE" --profile worker up -d ;;
  obs)    docker compose -f "$COMPOSE_FILE" --profile obs    up -d ;;
esac

