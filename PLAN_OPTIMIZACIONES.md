# Plan de Optimizaciones de Performance - Upload de Videos

## üéØ Objetivo

**Meta**: Lograr **<1s** de tiempo de respuesta para upload de videos de **100MB** bajo condiciones de carga normal.

**Contexto**: Sistema debe soportar cientos de usuarios subiendo videos simult√°neamente.

---

## üìä L√≠nea Base Actual (Branch: develop)

### M√©tricas de Referencia

| Escenario | Tiempo | Estado |
|-----------|--------|--------|
| **9MB (1 VU)** | 338ms | ‚úÖ OK |
| **100MB (1 VU)** | 7.81s | ‚ùå Objetivo: <1s |
| **100MB (5 VUs)** | p95=38.06s | ‚ùå Cr√≠tico |

### An√°lisis de L√≠nea Base

**Bajo carga simple** (1 petici√≥n):
- 9MB: Excelente performance (338ms)
- 100MB: 7.81s indica bottleneck en I/O de red/archivos

**Bajo concurrencia** (5 VUs):
- `http_req_waiting` p95=**30.78s** (dominante)
- `http_req_sending` p95=7.9s
- Indica **cuello de botella cr√≠tico** en:
  - Base de datos (bloqueo de transacciones)
  - RabbitMQ (conexiones s√≠ncronas sin pool)

**M√©tricas de red**:
- `upload_rate_mb_s` p95=36.58 MB/s (aceptable)
- Throughput de red no es el problema principal

---

## ‚úÖ Optimizaciones Completadas

### Paso 0: RabbitMQ Healthcheck Fix ‚úÖ

**Archivo**: `compose.yaml`

**Problema**: RabbitMQ no llegaba a estado "healthy", bloqueando otros servicios.

**Soluci√≥n**:
```yaml
rabbitmq:
  healthcheck:
    timeout: 30s          # Antes: 15s
    start_period: 90s     # Nuevo: permite inicializaci√≥n completa
```

**Resultado**: RabbitMQ inicializa correctamente, servicios dependientes arrancan.

---

### Paso 0.1: Configuraci√≥n Nginx Local ‚úÖ

**Archivo**: `nginx/nginx.conf`

**Problema**: Nginx restart loop con error `host not found in upstream "__CORE_IP__:8000"`.

**Soluci√≥n**: Upstreams flexibles para local y cloud:
```nginx
# LOCAL: nombres de servicios Docker
upstream api_upstream { server anb_api:8000; keepalive 32; }
# ... otros upstreams ...

# MULTIHOST: IPs (comentado para local)
# upstream api_upstream { server __CORE_IP__:8000; keepalive 32; }
```

**Resultado**: Nginx funciona correctamente en local.

---

### Paso 0.2: Storage Backend Local ‚úÖ

**Archivo**: `core/app/config.py`

**Problema**: Error "Unable to locate credentials" al intentar usar S3 en local.

**Soluci√≥n**:
```python
STORAGE_BACKEND: str = "local"  # Para desarrollo local
```

**Resultado**: Almacenamiento funciona correctamente en local.

---

### Paso 0.3: RABBITMQ_URL Configuration ‚úÖ

**Archivo**: `compose.yaml`

**Problema**: Error "RabbitMQ configuration missing required env vars" desde anb_api.

**Soluci√≥n**:
```yaml
anb_api:
  environment:
    - RABBITMQ_URL=amqp://${RABBITMQ_DEFAULT_USER:-rabbit}:${RABBITMQ_DEFAULT_PASS:-rabbitpass}@rabbitmq:5672/
```

**Resultado**: RabbitMQ connectivity funcionando.

---

## üéØ Optimizaciones Pendientes (Orden de Implementaci√≥n)

### Fase 1: Reducci√≥n de Commits a Base de Datos

**Objetivo**: Reducir round-trips a PostgreSQL

**Cambio**: De 3 commits ‚Üí 1 commit usando `db.flush()` intermedio

**Archivos**:
- `core/app/services/uploads/local.py`

**Cambios**:
```python
# ANTES: 3 commits
db.add(video)
await db.commit()           # Commit 1
await db.refresh(video)

video.correlation_id = correlation_id
video.status = VideoStatus.processing
await db.commit()           # Commit 2
await db.refresh(video)

# Si falla MQ:
await db.commit()           # Commit 3 (rollback)

# DESPU√âS: 1 commit
db.add(video)
await db.flush()            # Obtiene ID sin commit

# ... l√≥gica ...
await db.commit()           # 1 solo commit al final
```

**Impacto esperado**: 15-20% mejora en tiempo de respuesta.

**Estado**: ‚è≥ Pendiente de implementar.

---

### Fase 2: Pool de Conexiones As√≠ncrono para RabbitMQ

**Objetivo**: Reducir overhead de conexiones RabbitMQ

**Problema**: Cada `RabbitPublisher` crea una nueva conexi√≥n s√≠ncrona.

**Soluci√≥n**: Pool singleton de Cliente Celery reutilizable con `kombu`.

**Archivos modificados**:
- `core/app/services/mq/celery_pool.py` (nuevo: pool singleton)
- `core/app/services/mq/rabbit.py` (refactorizado para usar pool)
- `core/requirements.txt` (agregar `kombu>=5.3`)

**Cambios**:
```python
# ANTES: Crear cliente Celery por mensaje
class RabbitPublisher:
    def __init__(self):
        self._celery = Celery('api_client', broker=broker_url)  # Nuevo cada vez
        # ... configuraci√≥n ...

# DESPU√âS: Pool singleton reutilizable
class CeleryPool:
    _instance = None
    def get_client(self):
        if not self._celery_app:
            self._initialize_celery()  # Solo una vez
        return self._celery_app

class RabbitPublisher:
    def __init__(self):
        pool = get_pool()
        self._celery = pool.get_client()  # Reutiliza
```

**Impacto medido**: 
- ‚úÖ Waiting time 9MB: -35% adicional (vs Fase 1)
- ‚úÖ Waiting time 100MB: -29% (vs Fase 1)
- ‚ö†Ô∏è Sending time 100MB: +28% (trade-off)
- ‚ùå Success rate 100MB: 20% (vs 100% Fase 1)

**Estado**: ‚úÖ Completada.

---

### Fase 3: Optimizaci√≥n de Pool PostgreSQL ‚úÖ

**Objetivo**: Ajustar pool de conexiones para carga concurrente

**Archivos modificados**:
- `core/app/database.py`

**Implementaci√≥n**:
```python
engine = create_async_engine(
    settings.DATABASE_URL,
    pool_size=20,           # Aumentar de default (5) a 20
    max_overflow=10,        # Permitir burst de conexiones
    pool_timeout=30,        # Timeout razonable
    pool_pre_ping=True,     # Health checks de conexiones
    future=True,
)
```

**Impacto medido**:
- ‚úÖ **100MB simple**: -60% vs Fase 1 (2.74s vs 6.94s)
- ‚úÖ **9MB concurrencia**: -34% vs Fase 2 (2.13s vs 3.21s)
- ‚úÖ **100MB concurrencia**: -23% vs Fase 2 (21.28s vs 27.69s)
- ‚úÖ **Success rate**: 100% para 100MB (vs 20% Fase 2)
- ‚úÖ **Sending time**: -39% vs Fase 2 (6.91s vs 11.4s)

**Diagn√≥stico**: El pool PostgreSQL optimizado resuelve la regresi√≥n de Fase 2 y mejora dram√°ticamente 100MB simple.

**Estado**: ‚úÖ Completada.

---

### Fase 4: Investigaci√≥n de Bloqueos en Base de Datos

**Objetivo**: Identificar deadlocks o locks excesivos

**Acciones**:
1. Revisar logs de PostgreSQL durante prueba de carga
2. Verificar isolation level de transacciones
3. Verificar √≠ndices en tabla `videos`:
   - `idx_video_user_status` en (user_id, status)
   - `idx_video_created` en created_at
4. Considerar `SELECT FOR UPDATE NOWAIT` para casos cr√≠ticos

**Archivos**:
- `core/app/models/video.py` (verificar √≠ndices)
- `core/app/database.py` (isolation level)

**Impacto esperado**: Resolver problema de concurrencia si existe.

**Estado**: ‚è≥ Pendiente de investigar.

---

### Fase 5: Desactivar Buffering en Nginx para Uploads ‚úÖ

**Objetivo**: Reducir latencia de buffering

**Archivo modificado**:
- `nginx/nginx.conf` (agregado location espec√≠fico para uploads)

**Implementaci√≥n**:
```nginx
location /api/videos/upload {
    proxy_pass http://api_upstream/videos/upload;
    proxy_request_buffering off;
    proxy_buffering off;
}
```

**Impacto medido**:
- ‚úÖ **9MB simple**: Mejor√≥ 20% (370ms ‚Üí 297ms)
- ‚úÖ **100MB simple**: Mejor√≥ 21% (2.74s ‚Üí 2.16s)
- ‚úÖ **9MB concurrencia**: Mejor√≥ 33% (2.13s ‚Üí 1.43s)
- ‚úÖ **100MB waiting**: Mejor√≥ 36% (15.3s ‚Üí 9.84s)
- ‚ùå **100MB sending**: Empeor√≥ 103% (6.91s ‚Üí 14.02s)

**Diagn√≥stico**: Buffering OFF mejora casos simples pero empeora archivos grandes bajo concurrencia. Nginx sin buffer no puede optimizar I/O correctamente.

**Estado**: ‚úÖ Completada (pero REGRESI√ìN en 100MB concurrencia)

---

### Fase 6: Async File Writing con Streaming

**Objetivo**: Escritura de archivos en chunks as√≠ncronos

**Problema anterior**: Intentamos `aiofiles` leyendo todo en memoria ‚Üí empeor√≥ performance.

**Soluci√≥n correcta**: Streaming por chunks:
```python
async def _async_save_file(self, fileobj, dest_path):
    async with aiofiles.open(dest_path, 'wb') as f:
        while chunk := await asyncio.to_thread(fileobj.read, 8192):
            await f.write(chunk)
```

**Archivos**:
- `core/app/services/uploads/local.py`

**Impacto esperado**: 15-20% mejora en sending time para archivos grandes.

**Estado**: ‚è≥ Pendiente de implementar (versi√≥n correcta).

---

### Fase 7: Escalamiento Horizontal de Workers

**Objetivo**: Procesar videos m√°s r√°pido (no afecta upload)

**Cambios** en `compose.yaml`:
```yaml
worker:
  deploy:
    replicas: 3  # Antes: 1
```

**Impacto esperado**: Mejora procesamiento as√≠ncrono, no upload.

**Estado**: ‚è≥ Pendiente de implementar.

---

## üîç An√°lisis del Problema Principal

### Waiting Time Bajo Concurrencia

**M√©trica cr√≠tica**: `http_req_waiting` p95=30.78s (vs 7.81s aislado)

**Indica**:
1. Bloqueos en base de datos (m√°s probable)
2. RabbitMQ sin pool de conexiones
3. Transacciones demasiado largas
4. Falta de √≠ndices adecuados

**Hip√≥tesis principales**:
- Transacciones bloquean tabla `videos` durante el commit
- Cada mensaje a RabbitMQ abre conexi√≥n nueva
- Pool de PostgreSQL insuficiente para 5 VUs concurrentes

**Acci√≥n**: Implementar Fases 1, 2, 3 y 4 en orden, midiendo despu√©s de cada una.

---

## üìã Orden Recomendado de Implementaci√≥n

1. ‚úÖ **Fase 0**: Configuraci√≥n inicial (completado)
2. ‚úÖ **Fase 0.1-0.3**: Fixes de infraestructura (completado)
3. ‚úÖ **Fase 1**: Reducci√≥n de commits DB (completado)
4. ‚úÖ **Fase 2**: Pool Celery singleton (completado)
5. ‚úÖ **Fase 3**: Optimizaci√≥n pool PostgreSQL (completado)
6. ‚úÖ **Fase 5**: Nginx buffering OFF (completado pero REGRESI√ìN)
7. ‚è≥ **Fase 4**: Investigaci√≥n bloqueos DB
8. ‚è≥ **Fase 6**: Async file writing streaming
9. ‚è≥ **Fase 7**: Escalamiento workers

---

## üß™ Proceso de Validaci√≥n

### Despu√©s de Cada Fase:

1. **Ejecutar pruebas**:
   ```bash
   # 1 VU - 100MB
   k6 run K6/0unaPeticion.js \
     -e BASE_URL=http://localhost:8080 \
     -e FILE_PATH='/path/to/100MB.mov' \
     -e TITLE='Test' \
     -e ACCESS_TOKEN='...'

   # 5 VUs - 100MB
   k6 run K6/1sanidad.js \
     -e BASE_URL=http://localhost:8080 \
     -e FILE_PATH='/path/to/100MB.mov' \
     -e TITLE='Test' \
     -e ACCESS_TOKEN='...'
   ```

2. **Documentar resultados**:
   - Tiempo 1 VU
   - Tiempo p95 bajo 5 VUs
   - Waiting vs Sending time

3. **Decidir**: Continuar con siguiente fase o investigar problemas

---

## ‚ö†Ô∏è Lecciones Aprendidas

### ‚úÖ Lo que FUNCIONA:
- Ajustar healthchecks de infraestructura
- Separar configuraci√≥n local vs cloud

### ‚ùå Lo que NO funciona:
- `aiofiles` sin streaming (leer todo en memoria) ‚Üí empeora performance
- Quitar `seek(0)` antes de leer ‚Üí causa archivos vac√≠os

### üéì Principios:
1. **Medir primero**, optimizar despu√©s
2. **Una fase a la vez**, midiendo impacto
3. **Async no siempre es mejor**: overhead puede empeorar
4. **Concurrencia es el problema real**, no velocidad individual

---

## üìà M√©tricas de √âxito

**Meta final**: 100MB en **<1s** bajo condiciones normales

**Indicadores**:
- ‚úÖ 1 VU: <1s para 100MB
- ‚úÖ 5 VUs: p95 <3s para 100MB
- ‚úÖ Waiting time <30% del total
- ‚úÖ Success rate >99%

---

**√öltima actualizaci√≥n**: 2025-11-01  
**Branch**: develop  
**L√≠nea base**: ver `BASELINE.md`
